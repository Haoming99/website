<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Haoming Li</title>

    <meta name="author" content="Haoming Li">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Haoming Li
                </p>
                <p>I am a research assistant in the <a href="https://www.grasp.upenn.edu/" target="_blank">General Robotics, Automation, Sensing and Perception (GRASP) Laboratory</a> at the <a href="https://www.seas.upenn.edu/" target="_blank">University of Pennsylvania</a> under the supervision of <a href="https://www.cis.upenn.edu/~kostas/" target="_blank">Prof. Kostas Daniilidis</a>. Prior to that, I completed my master's degree in Electrical Engineering at the <a href="https://www.seas.upenn.edu/" target="_blank">University of Pennsylvania</a> co-supervised by <a href="https://nbfigueroa.github.io/" target="_blank">Prof. Nadia Figueroa</a> and <a href="https://pratikac.github.io/" target="_blank">Prof. Pratik Chaudhari</a>. I recieved my bachelor's degree in Electrical and Information Engrineering at the <a href="https://en.cugb.edu.cn/" target="_blank">China University of Geosciences, Beijing</a> advised by <a href="https://people.ucas.ac.cn/~_yanliu?language=en" target="_blank">Prof. Yan Liu</a> and <a href="https://people.ucas.ac.cn/~kmchen" target="_blank">Prof. Keming Chen</a>. </p>

                <p>My research interests generally lie in robotics, 3D vision, and generative modeling. I am currently working on 3D shape completion for robotic grasping under the supervision of <a href="https://www.cis.upenn.edu/~kostas/" target="_blank">Prof. Kostas Daniilidis</a>. Before that, I worked with <a href="https://nbfigueroa.github.io/" target="_blank">Prof. Nadia Figueroa</a> on real-time 3D mapping for safe robotic navigation and neural implicit SLAM. Before coming to Penn, I participated in projects about ground-penetrating radar object detection and remote sensing image segmentation. </p>

                <p>You can reach me at <em>lihaomingforreal (att) gmail (dott) com</em>.</p>

                <p style="text-align:center">
                  <a href="mailto:lihaomingforreal@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/cv.pdf">CV</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/lhm.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/lhm.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in robotics, 3D vision, and machine learning. My ultimate goal is to enable robots to learn and behave like humans.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>




              
  <tr onmouseout="switchImage('project1-image', 'images/grasping.gif')" 
      onmouseover="switchImage('project1-image', 'images/net_work.png')">
    <td style="padding:20px;width:25%;vertical-align:middle">
      <div id="image-container">
        <img id="project1-image" src="images/grasping.gif" width="300">
      </div>
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
          <strong>
      <a href="https://github.com/Haoming99/DiffGrasp/tree/main" target="_blank">
        DiffGrasp: Diffusion-based 3D Shape Completion for Robust Robotic Grasping
      </a>
    </strong>
      <br>
      <strong>Haoming Li</strong>*, <a href="https://jiangwenpl.github.io/">Wen Jiang</a>*, <a href="https://www.cis.upenn.edu/~kostas/">Kostas Daniilidis</a>
      <br>
      Advisor: <a href="https://www.cis.upenn.edu/~kostas/">Kostas Daniilidis</a>
      <br>
      Paper in perparation 
      <br>
      <a href="https://github.com/Haoming99/DiffGrasp/tree/main" target="_blank">
        Code
      </a>
      <br>
      <p></p>
      <p>We propose DiffGrasp, a diffusion-based 3D shape completion method for robust robotic grasping. 
      Our method compresses 3D shapes into a lower-dimensional latent space and takes the shape completion as a reverse diffusion process conditioned on a partial point cloud to produce multimodal but realistic complete 3D shapes. 
      At runtime, our method takes a single view depth image as input and generates accurate grasp poses based on the completed 3D shape. 
    </td>
  </tr>



            

<tr onmouseout="dualfont_stop()" onmouseover="dualfont_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <!-- Replace the src with your own image -->
    <img src='images/cbf0.gif' width="300">
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
<strong>Reactive Collision Avoidance using Neural Signed Distance Functions and
Neural Radiance Fields</strong>
    <br>
Advisor: <a href="https://nbfigueroa.github.io/">Nadia Figueroa</a>
    <br>
    <p></p>
    <p>We propose a method that maps RGB-D streams to signed distance functions (SDFs) for real-time collision avoidance. Our model is a MLP-based continuous learning system that takes a stream of posed depth images as inputs and reconstructs 3D scenes in real-time.
We construct control barrier functions (CBFs) using SDFs to ensure safe navigation by determining whether an control action is safe or unsafe. The experiments done in the Gazebo simulation environment demonstrated the effectiveness of our model in safe robotic navigation. </p>
  </td>
</tr>



            
<tr onmouseout="dualfont_stop()" onmouseover="dualfont_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <!-- Replace the src with your own image -->
    <img src='images/thesis.png' width="300">
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="images/thesis.pdf">
      <span class="papertitle">Towards Generalizable Robust Safe Robotic Systems via
Lipschitz Regularization</span>
    </a>
    <br>
    Advisor:  <a href="http://www.cs.cmu.edu/~asrivats/">Nadia Figueroa</a>,
    Co-advisor: <a href="https://pratikac.github.io/">Pratik Chaudhari</a>
    <br>
    <em>Master' Thesis</em>, 2024     <a href="images/thesis.pdf">
      <br>
      <a href="images/thesis.pdf">Paper</a>
    </a>
    <br>
    <p></p>
    <p>We propose a semantic-informed neural SLAM to enhance the generalization thus produce precise scene reconstruction and
robust camera tracking. We explore the benefits of semantic information to
refine both mapping and tracking processes. Additionally, we introduce a novel weight normalization and regularization to
increase network robustness against noises and perturbation. We evaluate our method on the Replica and the Neural RGBD datasets, demonstrating
its effectiveness in robotic navigation.</p>
  </td>
</tr>





<tr onmouseout="dualfont_stop()" onmouseover="dualfont_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <!-- Replace the src with your own image -->
    <img src='images/changedetection.png' width="300">
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://ieeexplore.ieee.org/document/9779962">
      <span class="papertitle">A Divided Spatial and Temporal Context Network for Remote Sensing Change Detection</span>
    </a>
    <br>
    Advisor: <a href="http://www.aircas.cas.cn/sourcedb/cn/expert/yjy/202306/t20230614_6778122.html">Keming Chen</a>
    <br>
    <em>IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</em>, 2022
    <br>
    <a href="https://ieeexplore.ieee.org/document/9779962">Paper</a>
    <p></p>
    <p> We introduce a transformer-based method to globally model spatial and temporal context in remote sensing change detection tasks. By introducing Transformer into modeling the global
context, the network can produce accurate segmentation masks for multitemporal remote sensing images. </p>
  </td>
</tr>



            

<tr onmouseout="dualfont_stop()" onmouseover="dualfont_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <!-- Replace the src with your own image -->
    <img src='images/ice.png' width="300">
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://ieeexplore.ieee.org/document/9321072/authors#authors">
      <span class="papertitle">Ice Crevasse Detection with Ground
Penetrating Radar using Faster R-CNN</span>
    </a>
    <br>
                <a href="https://people.ucas.ac.cn/~_yanliu?language=en">Yan Liu</a>,
                <strong>Haoming Li</strong>, 
                Mingzhe Hunang,
                <a href="https://people.ucas.ac.cn/~0007255?language=en">Deyuan Chen</a>,
                Bo Zhao,
    <br>
    <em>IEEE International Conference on Signal Processing</em>, 2020
    <br>
    <a href="https://ieeexplore.ieee.org/document/9321072/authors#authors">Paper</a>
    <p></p>
    <p>We propose an ice crevasse detection method based on Faster R-CNN achieving an
accuracy above 95% for safe navigation.</p>
  </td>
</tr>

            





          </tbody></table>
            

            
        </td>
      </tr>
    </table>
  </body>
</html>
