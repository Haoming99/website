<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Haoming Li</title>

    <meta name="author" content="Haoming Li">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Haoming Li
                </p>
                <p>I am a research assistant in the <a href="https://www.grasp.upenn.edu/" target="_blank">General Robotics, Automation, Sensing and Perception (GRASP) Laboratory</a> at the <a href="https://www.seas.upenn.edu/" target="_blank">University of Pennsylvania</a> under the supervision of <a href="https://www.cis.upenn.edu/~kostas/" target="_blank">Prof. Kostas Daniilidis</a>. Prior to that, I completed my master's degree in Electrical Engineering at the <a href="https://www.seas.upenn.edu/" target="_blank">University of Pennsylvania</a> co-supervised by <a href="https://nbfigueroa.github.io/" target="_blank">Prof. Nadia Figueroa</a> and <a href="https://pratikac.github.io/" target="_blank">Prof. Pratik Chaudhari</a>. I recieved my bachelor's degree in Electrical and Information Engrineering at the <a href="https://en.cugb.edu.cn/" target="_blank">China University of Geosciences, Beijing</a> advised by <a href="https://people.ucas.ac.cn/~_yanliu?language=en" target="_blank">Prof. Yan Liu</a> and <a href="https://people.ucas.ac.cn/~kmchen" target="_blank">Prof. Keming Chen</a>. </p>

                <p>My research interests revolve broadly around robotics, 3D vision, and generative modeling. I am currently working on 3D shape completion for robotic grasping under the supervision of <a href="https://www.cis.upenn.edu/~kostas/" target="_blank">Prof. Kostas Daniilidis</a>. Before that, I worked with <a href="https://nbfigueroa.github.io/" target="_blank">Prof. Nadia Figueroa</a> on real-time 3D mapping for safe robotic navigation during master's. Before coming to Penn, I participated in projects about ground-penetrating radar object detection and remote sensing image segmentation. </p>

                <p>You can reach me at <em>lihaomingforreal (att) gmail (dott) com</em>.</p>

                <p style="text-align:center">
                  <a href="mailto:lihaomingforreal@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/cv.pdf">CV</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/lhm.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/lhm.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in robotics, 3D vision, human-robot interaction, and machine learning.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>




              
<tr onmouseout="dualfont_stop()" onmouseover="dualfont_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div id="image-container">
      <img id="sequential-image" src='images/grasping.gif' width="300">
    </div>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <strong>DiffGPD: Diffusion-based Shape Completion Network for Robot Grasping</strong>
    <br>
    Advisor: <a href="https://www.cis.upenn.edu/~kostas/">Kostas Daniilidis</a>
    <br>
    Ongoing
    <br>
    <p></p>
    <p>We propose DiffGPD, a diffusion-based 3D shape completion method for robotic grasping. 
    Our method compresses 3D shapes into a lower-dimensional latent space and takes the shape completion as a reverse diffusion process conditioned on a partial point cloud to produce multimodal but realistic complete 3D shapes. 
    At runtime, our method takes a single view depth image as input and generates accurate grasp poses based on the completed 3D shape. 
  </td>
</tr>


            

<tr onmouseout="dualfont_stop()" onmouseover="dualfont_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <!-- Replace the src with your own image -->
    <img src='images/cbf0.gif' width="300">
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
<strong>Reactive Collision Avoidance using Neural Signed Distance Functions and
Neural Radiance Fields</strong>
    <br>
Advisor: <a href="https://nbfigueroa.github.io/">Nadia Figueroa</a>
    <br>
    <p></p>
    <p>We propose a method that maps RGB-D streams to signed distance functions for real-
time collision avoidance. Our model is a MLP-based continuous learning system that takes a stream of posed depth images as input and reconstructs 3D scenes represented by signed distance fields which are then used to construct control barrier functions in real-time.
The learned control barrier functions ensure safe robotic navigation by allowing our controller to determine whether an action is safe or unsafe. The experiments done in the Gazebo simulation environment demonstrated its utility for downstream planners in domains
from navigation to manipulation. </p>
  </td>
</tr>



            
<tr onmouseout="dualfont_stop()" onmouseover="dualfont_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <!-- Replace the src with your own image -->
    <img src='images/thesis.png' width="300">
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="images/thesis.pdf">
      <span class="papertitle">Towards Generalizable Robust Safe Robotic Systems via
Lipschitz Regularization</span>
    </a>
    <br>
    Advisor:  <a href="http://www.cs.cmu.edu/~asrivats/">Nadia Figueroa</a>,
    Co-advisor: <a href="https://pratikac.github.io/">Pratik Chaudhari</a>
    <br>
    <em>Master' Thesis</em>, 2024
    <br>
    <p></p>
    <p>We propose a semantic-informed neural SLAM to enhance the generalization
capabilities and provide more precise and detailed scene reconstructions and
robust camera tracking. Our contributions include a novel weight normalization and regularization to
increase network robustness. Additionally, we explore the benefits of semantic information to
refine both mapping and tracking processes. The proposed neural SLAM has been evaluated on the Replica and Neural RGBD datasets, demonstrating
its potential to impact the fields of robotic navigation.</p>
  </td>
</tr>





<tr onmouseout="dualfont_stop()" onmouseover="dualfont_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <!-- Replace the src with your own image -->
    <img src='images/changedetection.png' width="300">
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://ieeexplore.ieee.org/document/9779962">
      <span class="papertitle">A Divided Spatial and Temporal Context Network for Remote Sensing Change Detection</span>
    </a>
    <br>
    Advisor: <a href="http://www.aircas.cas.cn/sourcedb/cn/expert/yjy/202306/t20230614_6778122.html">Keming Chen</a>
    <br>
    <em><strong>IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</strong></em>, 2022
    <br>
    <p></p>
    <p> We introduce a divided spatial and temporal context modeling
network to tackle the shortcomings of CNN-based methods, which is tokens-based and
passes the global context by well-modeled tokens. By introducing the Transformer into modeling the global
context, the network can produce more accurate segmentation masks for temporal remote sensing images. </p>
  </td>
</tr>



            

<tr onmouseout="dualfont_stop()" onmouseover="dualfont_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <!-- Replace the src with your own image -->
    <img src='images/ice.png' width="300">
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://ieeexplore.ieee.org/document/9321072/authors#authors">
      <span class="papertitle">Ice Crevasse Detection with Ground
Penetrating Radar using Faster R-CNN</span>
    </a>
    <br>
                <a href="https://people.ucas.ac.cn/~_yanliu?language=en">Yan Liu</a>,
                <strong>Haoming Li</strong>, 
                Mingzhe Hunang,
                <a href="https://people.ucas.ac.cn/~0007255?language=en">Deyuan Chen</a>,
                Bo Zhao,
    <br>
    <em><strong>IEEE International Conference on Signal Processing</strong></em>, 2020
    <br>
    <p></p>
    <p>We propose an ice crevasse detection method based on Faster R-CNN achieving an
accuracy above 95% for safe robotic navigation.</p>
  </td>
</tr>

            





          </tbody></table>
            

            
        </td>
      </tr>
    </table>
  </body>
</html>
