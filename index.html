<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Haoming Li</title>

    <meta name="author" content="Haoming Li">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Haoming Li
                </p>
                <p>I am a research assistant in the <a href="https://www.grasp.upenn.edu/" target="_blank">General Robotics, Automation, Sensing and Perception (GRASP) Laboratory</a> at the <a href="https://www.seas.upenn.edu/" target="_blank">University of Pennsylvania</a> under the supervision of <a href="https://www.cis.upenn.edu/~kostas/" target="_blank">Prof. Kostas Daniilidis</a>. Prior to that, I completed my master's degree in Electrical Engineering at the <a href="https://www.seas.upenn.edu/" target="_blank">University of Pennsylvania</a> co-supervised by <a href="https://nbfigueroa.github.io/" target="_blank">Prof. Nadia Figueroa</a> and <a href="https://pratikac.github.io/" target="_blank">Prof. Pratik Chaudhari</a>. I recieved my bachelor's degree in Electrical and Information Engrineering at the <a href="https://en.cugb.edu.cn/" target="_blank">China University of Geosciences, Beijing</a> advised by <a href="https://people.ucas.ac.cn/~_yanliu?language=en" target="_blank">Prof. Yan Liu</a> and <a href="https://people.ucas.ac.cn/~kmchen" target="_blank">Prof. Keming Chen</a>. </p>

                <p>My research interests revolve broadly around robotics, 3D vision, and machine learning. I am currently working on 3D shape completion for robotic manipulation under the supervision of <a href="https://www.cis.upenn.edu/~kostas/" target="_blank">Prof. Kostas Daniilidis</a>. Before that, I worked with <a href="https://nbfigueroa.github.io/" target="_blank">Prof. Nadia Figueroa</a> on real-time 3D mapping for safe robotic navigation during master's. Before coming to Penn, I participated in projects about ground-penetrating radar object detection and remote sensing image change segmentation. </p>

                <p>You can reach me at <em>lihaomingforreal (att) gmail (dott) com</em>.</p>

                <p style="text-align:center">
                  <a href="mailto:lihaomingforreal@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/cv202409.pdf">CV</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/JonBarron_circle.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in robotics, 3D vision, human-robot interaction, and machine learning.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>




              
            <tr onmouseout="dualfont_stop()" onmouseover="dualfont_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='dualfont_image'><img src='images/dualfont_after.png'></div>
                  <img src='images/dualfont_before.png'>
                </div>
                <script type="text/javascript">
                  function dualfont_start() {
                    document.getElementById('dualfont_image').style.opacity = "1";
                  }

                  function dualfont_stop() {
                    document.getElementById('dualfont_image').style.opacity = "0";
                  }
                  dualfont_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2109.06627">
                  <span class="papertitle">Diffusion-based Shape Completion Network for Robot Grasping</span>
                </a>
                <br>
                <a href="http://www.cs.cmu.edu/~asrivats/">Nikita Srivatsan</a>,
                <a href="http://siwu.io/">Si Wu</a>,
                <strong>Jonathan T. Barron</strong>,
                <a href="http://cseweb.ucsd.edu/~tberg/">Taylor Berg-Kirkpatrick</a>
                <br>
                <em>EMNLP</em>, 2021
                <br>
                <p></p>
                <p>VAEs can be used to disentangle a font's style from its content, and to generalize to characters that were never observed during training.</p>
              </td>
            </tr>



            
            <tr onmouseout="mipnerf_stop()" onmouseover="mipnerf_start()"  bgcolor="#ffffd0">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='mipnerf_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/mipnerf_ipe_yellow.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/mipnerf_ipe_yellow.png' width="160">
                </div>
                <script type="text/javascript">
                  function mipnerf_start() {
                    document.getElementById('mipnerf_image').style.opacity = "1";
                  }

                  function mipnerf_stop() {
                    document.getElementById('mipnerf_image').style.opacity = "0";
                  }
                  mipnerf_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="http://jonbarron.info/mipnerf">
                  <span class="papertitle">Reactive Collision Avoidance using Neural Signed Distance Functions and
Neural Radiance Fields</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>,
                <a href="https://bmild.github.io/">Ben Mildenhall</a>,
                <a href="http://matthewtancik.com/">Matthew Tancik</a>, <br>
                <a href="https://phogzone.com/">Peter Hedman</a>,
                <a href="http://www.ricardomartinbrualla.com/">Ricardo Martin-Brualla</a>,
                <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>
                <br>
                <em>ICCV</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation, Best Paper Honorable Mention)</strong></font>
                <br>
                <a href="http://jonbarron.info/mipnerf">project page</a>
                /
                <a href="https://arxiv.org/abs/2103.13415">arXiv</a>
                /
                <a href="https://youtu.be/EpH175PY1A0">video</a>
                /
                <a href="https://github.com/google/mipnerf">code</a>
                <p></p>
                <p>NeRF is aliased, but we can anti-alias it by casting cones and prefiltering the positional encoding function.</p>
              </td>
            </tr> 



            
            <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/nerfbake_15.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/nerfbake_160.png' width="160">
                </div>
                <script type="text/javascript">
                  function nerfbake_start() {
                    document.getElementById('nerfbake_image').style.opacity = "1";
                  }

                  function nerfbake_stop() {
                    document.getElementById('nerfbake_image').style.opacity = "0";
                  }
                  nerfbake_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="http://nerf.live">
                <span class="papertitle">Towards Generalizable Robust Safe Robotic Systems via
Lipschitz Regularization</span>
                </a>
                <br>
                <a href="https://phogzone.com/">Peter Hedman</a>,
                <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
                <a href="https://bmild.github.io/">Ben Mildenhall</a>,
                <strong>Jonathan T. Barron</strong>,
                <a href="https://www.pauldebevec.com/">Paul Debevec</a>
                <br>
                <em>ICCV</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                <br>
                <a href="http://nerf.live">project page</a>
                /
                <a href="https://arxiv.org/abs/2103.14645">arXiv</a>
                /
                <a href="https://www.youtube.com/watch?v=5jKry8n5YO8">video</a>
                /
                <a href="https://nerf.live/#demos">demo</a>
                <p></p>
                <p>Baking a trained NeRF into a sparse voxel grid of colors and features lets you render it in real-time in your browser.</p>
              </td>


              

            <tr onmouseout="nerfie_stop()" onmouseover="nerfie_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='nerfie_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/nerfie_after.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/nerfie_before.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function nerfie_start() {
                    document.getElementById('nerfie_image').style.opacity = "1";
                  }
                  function nerfie_stop() {
                    document.getElementById('nerfie_image').style.opacity = "0";
                  }
                  nerfie_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://nerfies.github.io/">
                  <span class="papertitle">Improving Robustness by Restricting Estimated Lipschitz Constants of
Neural Networks</span>
                </a>
                <br>
                
                <a href="https://keunhong.com">Keunhong Park</a>,
                <a href="https://utkarshsinha.com">Utkarsh Sinha</a>,
                <strong>Jonathan T. Barron</strong>, <br>
                <a href="http://sofienbouaziz.com">Sofien Bouaziz</a>,
                <a href="https://www.danbgoldman.com">Dan B Goldman</a>,
                <a href="https://homes.cs.washington.edu/~seitz/">Steven M. Seitz</a>,
                <a href="http://www.ricardomartinbrualla.com">Ricardo-Martin Brualla</a>
                <br>
                <em>ICCV</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                <br>
                <a href="https://nerfies.github.io/">project page</a> /
                <a href="https://arxiv.org/abs/2011.12948">arXiv</a> /
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA">video</a>
                <p></p>
                <p>Building deformation fields into NeRF lets you capture non-rigid subjects, like people.
                </p>
              </td>
            </tr> 


            
            <tr onmouseout="c5_stop()" onmouseover="c5_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='c5_image'>
                    <img src='images/c5_after.jpg' width="160"></div>
                  <img src='images/c5_before.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function c5_start() {
                    document.getElementById('c5_image').style.opacity = "1";
                  }

                  function c5_stop() {
                    document.getElementById('c5_image').style.opacity = "0";
                  }
                  c5_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2011.11890">
                  <span class="papertitle">A Divided Spatial and Temporal Context Network for Remote Sensing Change Detection</span>
                </a>
                <br>
                <a href="https://sites.google.com/corp/view/mafifi">Mahmoud Afifi</a>,
                <strong>Jonathan T. Barron</strong>,
                <a href="http://www.chloelegendre.com/">Chloe LeGendre</a>,
                <a href="https://research.google/people/105312/">Yun-Ta Tsai</a>,
                <a href="https://www.linkedin.com/in/fbleibel/">Francois Bleibel</a>
                <br>
                <em>IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing </em>, 2022
                <br>
                <p></p>
                <p>
                  With some extra (unlabeled) test-set images, you can build a hypernetwork that calibrates itself at test time to previously-unseen cameras.
                </p>
              </td>
            </tr> 


            
            <tr onmouseout="dualdefocus_stop()" onmouseover="dualdefocus_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='dualdefocus_image'>
                    <img src='images/dualdefocus_after.jpg' width="160"></div>
                  <img src='images/dualdefocus_before.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function dualdefocus_start() {
                    document.getElementById('dualdefocus_image').style.opacity = "1";
                  }

                  function dualdefocus_stop() {
                    document.getElementById('dualdefocus_image').style.opacity = "0";
                  }
                  dualdefocus_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://imaging.cs.cmu.edu/dual_pixels/">
                  <span class="papertitle">Ice Crevasse Detection with Ground
Penetrating Radar using Faster R-CNN</span>
                </a>
                <br>
                <a href="https://shumianxin.github.io/">Yan Liu</a>,
                <strong>Haoming Li</strong>, <br>
                <a href="https://pratulsrinivasan.github.io/">Mingzhe Huang</a>,
                <a href="http://people.csail.mit.edu/jiawen/">Deyuan Chen</a>,
                <a href="https://www.cs.cmu.edu/~igkioule/">Bo Zhao</a>,
                <br>
                <em>ICSP</em>, 2020 &nbsp <font color="black"><strong>(Oral Presentation)</strong></font>
                <br>
                <a href="https://github.com/cmu-ci-lab/dual_pixel_defocus_estimation_deblurring">paper</a>
                <br>
                <p></p>
                <p>
                 We proposed an ice crevasse detection method based on Faster R-CNN achieving an
accuracy above 95%. for robotic navigation.
                </p>
              </td>
            </tr> 




          </tbody></table>
            

            
        </td>
      </tr>
    </table>
  </body>
</html>
